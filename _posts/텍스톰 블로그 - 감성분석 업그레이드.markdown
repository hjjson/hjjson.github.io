
---

안녕하세요. 텍스톰에서 NLP를 연구하고 있는 데이터사이언스연구소의 강지훈 주임연구원입니다.

오늘은 감성분석을 업그레이드하게 된 이유와 새로 도입한 모델과의 성능 비교 그리고 향후 발전 방향에 대해 설명드리겠습니다.

# 1. Naive Bayes 알고리즘
---

기존 텍스톰에서는 Naive Bayes 알고리즘을 사용한 문서기반 감성분석을 제공하고 있었습니다. Naive Bayes는 사전확률에 기반하여 사후확률을 추론하는 알고리즘입니다.
감성분석을 예로 들면, 사전확률은 각 단어들이 감정(긍정/부정/중립)에 속할 확률이고 사후확률은 주어진 문서를 구성하는 각 단어들의 감정 확률로 계산한 문서의 감정 확률입니다.
여기서 각 단어들이 긍정/부정/중립에 속할 확률은 유저가 제공한 학습 데이터를 바탕으로 계산됩니다. 
### 1.1 Naive Bayes 알고리즘의 작동 방식
Naive Bayes는 간단하게 감정의 발생 확률 P(Sentiment)과 감정 내 단어들이 발생할 확률 P(Word|Sentiment)의 곱으로 계산됩니다.
여기서 감정의 발생 확률 P(S)은 학습한 데이터의 감성 분포를 사용합니다. 예를 들면, 학습에 사용한 데이터가 100개이고 그 중에서 긍정으로 라벨링 된 문서가 50개, 부정으로 라벨링 된 문서가 30개, 중립으로 라벨링된 문서가 20개라면 긍정의 발생 확률은 0.5, 부정의 발생 확률은 0.3 중립의 발생 확률은 0.2로 계산할 수 있습니다.
감정 내 단어들이 발생할 확률 P(Word|Sentiment)은 특정 감정을 가진 모든 문서에 포함된 단어들의 빈도수 중에서 특정 단어의 빈도수로 비율을 계산합니다. 예를 들어 긍정으로 라벨링 된 문서 50개 안에 포함된 모든 단어를 세었을 때 500개이고 그 중에서 '재미있다'라는 단어가 50번 나타났으면, P(재미있다|긍정)은 0.1로 계산할 수 있습니다.
그리고 새로운 문서의 감정을 분류할 때는 각 감정별로 확률값을 계산한 후, 최대 확률값을 나타내는 감정을 해당 문서의 감정으로 분류합니다.
### 1.2 장점
이처럼 단어별 감성분포를 계산할 때 빈도수만 사용하기 때문에 학습 과정이 간단하고 빠릅니다. 그리고 새로운 문장의 감성을 분류할 때도 문장에 속한 단어들의 확률을 곱하여 단순하게 계산이 가능하기 때문에 속도가 매우 빠르다는 장점이 있습니다. 
또한 성능면에서도 충분한 데이터로 학습했을 때 준수한 성능을 보입니다. 그래서 분류 문제에 일반적으로 많이 사용 되었습니다.
### 1.3 단점
하지만 단순히 빈도만 사용하기 때문에 성능에 한계를 가질 수 밖에 없습니다. 왜냐하면 동음이의어, 단어의 순서와 같은 문맥이 고려되지 않기 때문입니다. 예를 들어, Naive Bayes로 계산했을 때는 '안 커서 좋다'는 문장과 '커서 안 좋다'는 문장에 차이가 없습니다. 
결정적으로 Naive Bayes는 학습에 제공된 데이터'만'으로 모델이 구성되기 때문에 처음 본 단어가 있을 경우, 확률이 제대로 계산되지 않기 때문에 성능이 크게 떨어지게 됩니다. 그렇기 때문에 Naive Bayes 알고리즘은 '정확하게' 정답을 라벨링한 많은 종류의 데이터가 필요합니다.

이런 Naive Bayes의 단점을 극복하기 위해서 신경망 기반의 언어모델인 ELECTRA와 GPT를 도입하게 되었습니다.

# 2. 신경망 언어모델
---
신경망 언어모델은 언어의 복잡한 패턴을 처리할 수 있는 Transformer 구조와 사전훈련 모델의 장점으로 Naive Bayes가 가진 단점을 극복할 수 있습니다.
### 2.1 Transformer 구조의 장점
==<여기에 간단한 설명 추가>==
### 2.2 사전훈련 모델의 장점
ELECTRA의 기본 모델(base model)은 위키피디아와 책에서 수집한 33억개의 토큰으로 사전학습을 시켰으며 대형 모델(large-model)은 웹에서 수집한 데이터를 추가하여 330억개의 토큰으로 사전 학습시켰습니다. 
- 330억개의 토큰은 A4용지 기준으로 500만 페이지가 되며 300장 분량의 전공서적, 약 1만 7천권에 해당하는 방대한 양의 데이터입니다.

그리고 google에서 개발한 ELECTRA는 주로 영어 데이터로 학습되었기 때문에 한국어와 중국어 모델은 기본 ELECTRA 모델에 각 언어로 구성된 데이터로 추가 학습을 시킨 모델입니다.
- 텍스톰에서 제공하는 한국어 모델(electra-kor-base)은 [김기영](https://github.com/kiyoungkim1) 님이 뉴스, 블로그, 댓글, 리뷰 등으로 구성된 70GB의 한국어 데이터셋으로 학습시킨 모델을 사용했습니다.

즉, 100개 ~ 1,000개의 라벨링된 학습데이터로 모델을 파인튜닝 했을 때, 모델은 100개 ~ 1,000개의 데이터만 학습한 것이 아니라 사전훈련된 방대한 양의 데이터를 기반으로 학습하는 것입니다. 이러한 사전훈련 모델의 장점으로 

즉, Naive Bayes는 학습데이터로 제공되는 데이터만으로 

# 3. 성능 비교
---
그렇다면 위에 설명 드린 3가지 알고리즘을 감성분석에 적용했을 때 어느 정도로 성능에 차이를 보이는지 실험을 통해 알아보겠습니다.
### 3.1 데이터셋 구성
먼저 데이터셋은 박은정님이 공개하신 [영화 리뷰 데이터](https://github.com/e9t/nsmc)를 사용하였습니다. 이 데이터셋은 네이버 영화에서 리뷰와 함께 평점을 수집하여 1~4 점은 부정, 9~10점은 긍정 라벨링한 데이터입니다. 그리고 긍정과 부정의 비율이 5대5가 되도록 전체 64만 개의 리뷰에서  20만 개를 샘플링하였습니다.
다운로드 한 데이터에서 URL만 있거나 특수문자만 있는 데이터를 제거하고 전처리가 완료된 데이터셋을 무작위로 분할하여 학습용 데이터 60%, 테스트용 데이터 40%로 구성하였습니다.
### 3.2 모델 학습
Naive Bayes도 데이터의 형태나 분포의 가정에서 따라서 알고리즘이 세부적으로 구분되며, tokenizer에 따라서도 성능이 달라집니다. 테스트에 사용할 각 알고리즘의 세부 스팩은 다음과 같습니다.
- Naive Bayes : 텍스트 분류에 주로 사용되는 multinomial naive bayes를 사용하였으며, tokenizer로는 wordpiece tokenier를 사용하였습니다.
- Electra : 구글에서 개발한 기본형 모델([google/electra-base-discriminator](https://huggingface.co/google/electra-base-discriminator))에 한국어 corpus로 학습시킨 모델([kykim/electra-kor-base](https://huggingface.co/kykim/electra-kor-base))을 사용하였습니다.
- GPT : OpenAI에서 제공하는 API로 gpt-4o-mini 모델을 사용하였습니다. gpt-4o의 성능이 더 좋겠지만 빅데이터 분석 서비스를 제공하고 있기 때문에 서비스에 적용이 가능하도록 비용을 고려하여 mini 모델로 테스트하였습니다.
Naive Bayes와 ELECTRA는 구성된 데이터로 학습을 시켰으며, GPT는 범용적인 성능을 테스트 하기 위해서 zero-shot을 적용하였습니다.
### 3.3 테스트 결과

|               | Naive Bayes | ELECTRA<br>(electra-kor-base) | GPT<br>(gpt-4o-mini) |
| :-----------: | :---------: | :---------------------------: | :------------------: |
| **accuracy**  |   0.7748    |          **0.8560**           |        0.8476        |
| **precision** |   0.7753    |          **0.8573**           |        0.8571        |
|  **recall**   |   0.7748    |          **0.8560**           |        0.8476        |
| **f1 score**  |   0.7747    |          **0.8558**           |        0.8466        |
lectra와 gpt의 성능이 naive bayes보다 7 ~ 8%p 높다는 것을 확인할 수 있습니다.

한가지 의아하게 생각할 수 있습니다. 뛰어난 성능으로 모두를 놀라게 만드는 gpt가 electra보다 성능이 미세하지만 낮기 때문입니다. 그 이유는 electra는 14만 건의 

더 영화 리뷰의 문맥을 잘 이해할 수 있기 때문에 electra가 zero-shot을 사용한 gpt 대비 더 높은 성능을 보였습니다. 반대로 생각하면 gpt는 어떠한 추가 학습 없이도 약 7만 건의 데이터를 추가 학습한 electra와 1%p 차이로 거의 비슷한 성능을 보였습니다.

텍스톰이라는 서비스를 운영하는 입장에서는 유저들이 일일이 라벨링 하여 데이터를 올리기는 어렵기 때문에 라벨링 없이도 높은 성능을 보이는 GPT와 유저가 업로드한 데이터로 학습하여 GPT 대비 더 높은 성능을 보이는 ELECTRA 2가지 모델을 추가하게 되었습니다.
### 3.4 모델의 편향성

|                |       | naive bayes |    bert    |    gpt     |
| :------------: | :---: | :---------: | :--------: | :--------: |
|    전체 오답 수     |       |   17,301    |   11,065   |   11,710   |
| 긍정을 부정으로 잘못 판단 | 건수(건) |    9,507    |   4,332    |   8,984    |
|                | 비율(%) |     55      |     39     | ==**77**== |
| 부정을 긍정으로 잘못 판단 | 건수(건) |    7,794    |   6,733    |   2,726    |
|                | 비율(%) |     45      | ==**61**== |     23     |

1. 모델이 잘못 분석한 오답 중에서 긍정을 부정으로 그리고 부정을 긍정으로 잘못 분석한 경우의 비율을 보았을 때 naive bayes는 45대 55로 거의 비슷한 비율을 보였습니다. 하지만 ELECTRA는 부정을 긍정으로 판단한 비율이 61%로 상대적으로 더 높았고, gpt는 긍정을 부정으로 판단한 비율이 오답 중 77%로 더 편중된 결과를 보였습니다. 따라서 gpt는 전반적으로 영화 리뷰 데이터를 읽었을 때 부정적으로 해석하는 경향이 높았으며, bert는 긍정적으로 해석하는 경향을 보였습니다. 


1. 이를 통해 같은 문장을 해석할 때 모델별로 학습한 데이터의 분포에 따라서 편향성을 가지고 있다는 것을 알 수 있었습니다.
2. 
특정 영화에 대한 

평점 왜이러냐, 이정도 평점 받을 영화는 아닌거 같은데
처럼 리뷰 자체 외의 평점과 같은 메타데이터가 주어지지 않았기 때문에 모델이 제대로 판단하기 어려운 부분이 있었습니다.
답답해서 더 슬픈...
로봇이 인간보다 낮네 인간은 하등하고 잔인한 유인원에 불과하죠
와 같은 리뷰는 리뷰 자체로만 보면 부정적인 리뷰이지만
영화
드라마 넘 재미 있네요.. 보지도 않고 평점주는 초딩같은 ㅉㅉㅉ

라벨이 정확한지 확인할 수 없는 데이터가 포함되어 있습니다.
예를 들어서, '????' 나 '!!!!', '자세한 설명은 생략한다' 와 같은 리뷰는 맥락적 정보가 주어지지 않는 상황에서 사람도 긍정인지 부정인지 정확하게 판단하기 어렵기 때문에 데이터셋에서 제거하였습니다.

# 4. 향후 발전 방향
---
단순히 감성분석의 성능을 최대로 높이는 서
연구를 
아직 개선해야 할 부분이 많이 이
다음 2가지 방향으로 감성분석 연구를 이어가려고 합니다.
### 4.1. 속성기반 감성분석의 필요성
문서기반 감성분석은 문서 전체를 긍정/부정/중립으로 분류하기 때문에 하나의 문서 안에 여러 감정이 포함되어 있는 경우 이를 정확하게 판별하기 어렵습니다. 예를 들어서, 음식점의 리뷰를 분석 했을 때 맛과 분위기는 긍정적으로 생각하면서 동시에 서비스와 위생을 부정적으로 생각할 수 있습니다. 각 요소별로 보면 긍정과 부정이 명확하지만 전체 리뷰로 보면 긍정인지 부정인지 사람이 보아도 명확하게 말할 수 없을 것입니다.
아무리 GPT와 같이 뛰어난 모델을 사용한다 해도 이처럼 문서기반 감성분석 자체가 가지는 한계 때문에 분석이 잘못되었다고 느끼는 경우가 있을 것입니다. 
따라서 문서가 아니라 문장, 나아가 속성 단위로 감성분석을 해야지 더 정확하게 분석할 수 있습니다.
### 4.2. 지속적인 로컬 모델 개발
도메인을 정확하게 이해하고 100%의 감성분석을 하기 위해서는 학습 데이터가 필요합니다. 아무리 성능이 좋은 GPT를 사용한다고 해도 few-shot을 통해 예시를 넣어주지 않으면 도메인에 맞는 감성분석은 어렵습니다. 그리고 14만 건의 데이터를 학습한 ELECTRA가 gpt(zero-shot) 보다 성능이 높은 것에서 알 수 있듯이, 데이터가 많으면 많을수록 성능은 좋아집니다. 하지만 서비스를 
더 적은 데이터만 학습해도 높은 성능을 끌어낼 수 있는 

텍스톰 유저들이 더 적은 데이터로 높은 성능의 감성분석을 하기
> 범용적인 모델 만들기 / 지속적으로 모델을 업데이트








11월 내 유료화 > 논의 필요

서울본부와 함께 하는 대용량 감성분석 연구노트 작성 > 텍스톰 개선안 도출


텍스톰 분석 알고리즘 정확도 테스트
전반적인 분석의 신뢰도
텍스톰 스쿨 > 텍스톰 분석 모듈 사용
분석 결과가 정확하게 나오는지 성능 관련 검증을 받아야 한다는 피드백
인터넷에 TF 파이썬 코드와 질적으로 차별점
우리가 제공하는 TF가 과연 정확한가?